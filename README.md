[![PyPI version](https://badge.fury.io/py/nerpy.svg)](https://badge.fury.io/py/nerpy)
[![Downloads](https://pepy.tech/badge/nerpy)](https://pepy.tech/project/nerpy)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/nerpy.svg)](https://github.com/shibing624/nerpy/graphs/contributors)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_version](https://img.shields.io/badge/Python-3.5%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/nerpy.svg)](https://github.com/shibing624/nerpy/issues)
[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#Contact)

# NERpy
ğŸŒˆ Implementation of Named Entity Recognition using Python. 

**nerpy**å®ç°äº†BertSoftmaxã€BertCrfã€BertSpanç­‰å¤šç§å‘½åå®ä½“è¯†åˆ«æ¨¡å‹ï¼Œå¹¶åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šæ¯”è¾ƒäº†å„æ¨¡å‹çš„æ•ˆæœã€‚


**Guide**
- [Feature](#Feature)
- [Evaluation](#Evaluation)
- [Install](#install)
- [Usage](#usage)
- [Contact](#Contact)
- [Reference](#reference)


# Feature
### å‘½åå®ä½“è¯†åˆ«æ¨¡å‹
- [BertSoftmax](nerpy/ner_model.py)ï¼šBertSoftmaxåŸºäºBERTé¢„è®­ç»ƒæ¨¡å‹å®ç°å®ä½“è¯†åˆ«ï¼Œæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†BertSoftmaxæ¨¡å‹çš„è®­ç»ƒå’Œé¢„æµ‹

# Evaluation

### å®ä½“è¯†åˆ«

- è‹±æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†çš„è¯„æµ‹ç»“æœï¼š

| Arch | Backbone | Model Name | CoNLL-2003 | 
| :-- | :--- | :--- | :-: |
| BertSoftmax | bert-base-uncased | bert-softmax-base-uncased | - |

- ä¸­æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†çš„è¯„æµ‹ç»“æœï¼š

| Arch | Backbone | Model Name | CNER | PEOPLE | Avg | QPS |
| :-- | :--- | :--- | :-: | :-: | :-: | :-: |
| BertSoftmax | bert-base-chinese | bert4ner-base-chinese | 94.98 | 95.25 | 95.12 | 222 |

- æœ¬é¡¹ç›®releaseæ¨¡å‹çš„ä¸­æ–‡åŒ¹é…è¯„æµ‹ç»“æœï¼š

| Arch | Backbone | Model Name | CNER | PEOPLE | Avg | QPS |
| :-- | :--- | :---- | :-: | :-: | :-: | :-: |
| BertSoftmax | bert-base-chinese | shibing624/bert4ner-base-chinese | 94.98 | 95.25 | 95.12 | 222 |

è¯´æ˜ï¼š
- ç»“æœå€¼å‡ä½¿ç”¨F1
- ç»“æœå‡åªç”¨è¯¥æ•°æ®é›†çš„trainè®­ç»ƒï¼Œåœ¨testä¸Šè¯„ä¼°å¾—åˆ°çš„è¡¨ç°ï¼Œæ²¡ç”¨å¤–éƒ¨æ•°æ®
- `shibing624/bert4ner-base-chinese`æ¨¡å‹è¾¾åˆ°åŒçº§åˆ«å‚æ•°é‡SOTAæ•ˆæœï¼Œæ˜¯ç”¨BertSoftmaxæ–¹æ³•è®­ç»ƒï¼Œ
 è¿è¡Œ[examples/training_ner_model_file_demo.py](examples/training_ner_model_file_demo.py)ä»£ç å¯åœ¨å„æ•°æ®é›†å¤ç°ç»“æœ
- å„é¢„è®­ç»ƒæ¨¡å‹å‡å¯ä»¥é€šè¿‡transformersè°ƒç”¨ï¼Œå¦‚ä¸­æ–‡BERTæ¨¡å‹ï¼š`--model_name bert-base-chinese`
- ä¸­æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†ä¸‹è½½[é“¾æ¥è§ä¸‹æ–¹](#æ•°æ®é›†)
- QPSçš„GPUæµ‹è¯•ç¯å¢ƒæ˜¯Tesla V100ï¼Œæ˜¾å­˜32GB

# Demo

Demo: https://huggingface.co/spaces/shibing624/nerpy

![](docs/hf.png)

run example: [examples/gradio_demo.py](examples/gradio_demo.py) to see the demo:
```shell
python examples/gradio_demo.py
```

 
# Install
```
pip3 install torch # conda install pytorch
pip3 install -U nerpy
```

or

```
git clone https://github.com/shibing624/nerpy.git
cd nerpy
python3 setup.py install
```


# Usage

## å‘½åå®ä½“è¯†åˆ«

åŸºäºä¸­æ–‡`fine-tuned model`è¯†åˆ«å®ä½“ï¼š

```shell
>>> from nerpy import NERModel
>>> model = NERModel("bert", "shibing624/bert4ner-base-chinese")
>>> predictions, raw_outputs, entities = model.predict(["å¸¸å»ºè‰¯ï¼Œç”·ï¼Œ1963å¹´å‡ºç”Ÿï¼Œå·¥ç§‘å­¦å£«ï¼Œé«˜çº§å·¥ç¨‹å¸ˆ"], split_on_space=False)
entities: [('å¸¸å»ºè‰¯', 'PER'), ('1963å¹´', 'TIME')]
```

example: [examples/base_zh_demo.py](examples/base_zh_demo.py)

```python
import sys

sys.path.append('..')
from nerpy import NERModel

if __name__ == '__main__':
    # ä¸­æ–‡å®ä½“è¯†åˆ«æ¨¡å‹(BertSoftmax): shibing624/bert4ner-base-chinese
    model = NERModel("bert", "shibing624/bert4ner-base-chinese")
    sentences = [
        "å¸¸å»ºè‰¯ï¼Œç”·ï¼Œ1963å¹´å‡ºç”Ÿï¼Œå·¥ç§‘å­¦å£«ï¼Œé«˜çº§å·¥ç¨‹å¸ˆï¼ŒåŒ—äº¬ç‰©èµ„å­¦é™¢å®¢åº§å‰¯æ•™æˆ",
        "1985å¹´8æœˆ-1993å¹´åœ¨å›½å®¶ç‰©èµ„å±€ã€ç‰©èµ„éƒ¨ã€å›½å†…è´¸æ˜“éƒ¨é‡‘å±ææ–™æµé€šå¸ä»äº‹å›½å®¶ç»Ÿé…é’¢æä¸­ç‰¹ç§é’¢æå“ç§çš„è°ƒæ‹¨åˆ†é…å·¥ä½œï¼Œå…ˆåä»»ç§‘å‘˜ã€ä¸»ä»»ç§‘å‘˜ã€‚"
    ]
    predictions, raw_outputs, entities = model.predict(sentences)
    print(entities)
```

output:
```
[('å¸¸å»ºè‰¯', 'PER'), ('1963å¹´', 'TIME'), ('åŒ—äº¬ç‰©èµ„å­¦é™¢', 'ORG')]
[('1985å¹´', 'TIME'), ('8æœˆ', 'TIME'), ('1993å¹´', 'TIME'), ('å›½å®¶ç‰©èµ„å±€', 'ORG'), ('ç‰©èµ„éƒ¨', 'ORG'), ('å›½å†…è´¸æ˜“éƒ¨é‡‘å±ææ–™æµé€šå¸', 'ORG')]
```

- `shibing624/bert4ner-base-chinese`æ¨¡å‹æ˜¯BertSoftmaxæ–¹æ³•åœ¨ä¸­æ–‡PEOPLE(äººæ°‘æ—¥æŠ¥)æ•°æ®é›†è®­ç»ƒå¾—åˆ°çš„ï¼Œæ¨¡å‹å·²ç»ä¸Šä¼ åˆ°huggingfaceçš„
æ¨¡å‹åº“[shibing624/bert4ner-base-chinese](https://huggingface.co/shibing624/bert4ner-base-chinese)ï¼Œ
æ˜¯`nerpy.NERModel`æŒ‡å®šçš„é»˜è®¤æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡ä¸Šé¢ç¤ºä¾‹è°ƒç”¨ï¼Œæˆ–è€…å¦‚ä¸‹æ‰€ç¤ºç”¨[transformersåº“](https://github.com/huggingface/transformers)è°ƒç”¨ï¼Œ
æ¨¡å‹è‡ªåŠ¨ä¸‹è½½åˆ°æœ¬æœºè·¯å¾„ï¼š`~/.cache/huggingface/transformers`

#### Usage (HuggingFace Transformers)
Without [nerpy](https://github.com/shibing624/nerpy), you can use the model like this: 

First, you pass your input through the transformer model, then you have to apply the bio tag to get the entity words.

example: [examples/use_origin_transformers_demo.py](examples/use_origin_transformers_demo.py)

```python
import os
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification
from seqeval.metrics.sequence_labeling import get_entities

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# Load model from HuggingFace Hub
tokenizer = AutoTokenizer.from_pretrained("shibing624/bert4ner-base-chinese")
model = AutoModelForTokenClassification.from_pretrained("shibing624/bert4ner-base-chinese")
label_list = ['I-ORG', 'B-LOC', 'O', 'B-ORG', 'I-LOC', 'I-PER', 'B-TIME', 'I-TIME', 'B-PER']

sentence = "ç‹å®ä¼Ÿæ¥è‡ªåŒ—äº¬ï¼Œæ˜¯ä¸ªè­¦å¯Ÿï¼Œå–œæ¬¢å»ç‹åºœäº•æ¸¸ç©å„¿ã€‚"


def get_entity(sentence):
    tokens = tokenizer.tokenize(sentence)
    inputs = tokenizer.encode(sentence, return_tensors="pt")
    with torch.no_grad():
        outputs = model(inputs).logits
    predictions = torch.argmax(outputs, dim=2)
    char_tags = [(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].numpy())][1:-1]
    print(sentence)
    print(char_tags)

    pred_labels = [i[1] for i in char_tags]
    entities = []
    line_entities = get_entities(pred_labels)
    for i in line_entities:
        word = sentence[i[1]: i[2] + 1]
        entity_type = i[0]
        entities.append((word, entity_type))

    print("Sentence entity:")
    print(entities)


get_entity(sentence)
```
output:
```shell
ç‹å®ä¼Ÿæ¥è‡ªåŒ—äº¬ï¼Œæ˜¯ä¸ªè­¦å¯Ÿï¼Œå–œæ¬¢å»ç‹åºœäº•æ¸¸ç©å„¿ã€‚
[('ç‹', 'B-PER'), ('å®', 'I-PER'), ('ä¼Ÿ', 'I-PER'), ('æ¥', 'O'), ('è‡ª', 'O'), ('åŒ—', 'B-LOC'), ('äº¬', 'I-LOC'), ('ï¼Œ', 'O'), ('æ˜¯', 'O'), ('ä¸ª', 'O'), ('è­¦', 'O'), ('å¯Ÿ', 'O'), ('ï¼Œ', 'O'), ('å–œ', 'O'), ('æ¬¢', 'O'), ('å»', 'O'), ('ç‹', 'B-LOC'), ('åºœ', 'I-LOC'), ('äº•', 'I-LOC'), ('æ¸¸', 'O'), ('ç©', 'O'), ('å„¿', 'O'), ('ã€‚', 'O')]
Sentence entity:
[('ç‹å®ä¼Ÿ', 'PER'), ('åŒ—äº¬', 'LOC'), ('ç‹åºœäº•', 'LOC')]
```

### æ•°æ®é›†

#### ä¸­æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†


| æ•°æ®é›† | è¯­æ–™ | ä¸‹è½½é“¾æ¥ | æ–‡ä»¶å¤§å° |
| :------- | :--------- | :---------: | :---------: |
| **`CNERä¸­æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†`** | CNER(12ä¸‡å­—) | [CNER github](https://github.com/shibing624/nerpy/tree/main/examples/data/cner)| 1.1MB |
| **`PEOPLEä¸­æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†`** | äººæ°‘æ—¥æŠ¥æ•°æ®é›†ï¼ˆ200ä¸‡å­—ï¼‰ | [PEOPLE github](https://github.com/shibing624/nerpy/tree/main/examples/data/people)| 12.8MB |

CNERä¸­æ–‡å®ä½“è¯†åˆ«æ•°æ®é›†ï¼Œæ•°æ®æ ¼å¼ï¼š

```text
ç¾	B-LOC
å›½	I-LOC
çš„	O
å	B-PER
è±	I-PER
å£«	I-PER

æˆ‘	O
è·Ÿ	O
ä»–	O
```


## BertSoftmax æ¨¡å‹

BertSoftmaxå®ä½“è¯†åˆ«æ¨¡å‹ï¼ŒåŸºäºBERTçš„æ ‡å‡†åºåˆ—æ ‡æ³¨æ–¹æ³•ï¼š

Network structure:


<img src="docs/bert.png" width="500" />


æ¨¡å‹æ–‡ä»¶ç»„æˆï¼š
```
shibing624/bert4ner-base-chinese
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model_args.json
    â”œâ”€â”€ pytorch_model.bin
    â”œâ”€â”€ special_tokens_map.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ vocab.txt
```

#### BertSoftmax æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹
- åœ¨ä¸­æ–‡CNERæ•°æ®é›†è®­ç»ƒå’Œè¯„ä¼°`BertSoftmax`æ¨¡å‹

example: [examples/training_ner_model_file_demo.py](examples/training_ner_model_file_demo.py)

```shell
cd examples
python3 training_ner_model_file_demo.py --do_train --do_predict --num_epochs 5
```
- åœ¨è‹±æ–‡CoNLL-2003æ•°æ®é›†è®­ç»ƒå’Œè¯„ä¼°`BertSoftmax`æ¨¡å‹

example: [examples/training_ner_model_file_demo.py](examples/training_ner_model_file_demo.py)

```shell
cd examples
python3 training_ner_model_file_demo.py --do_train --do_predict --num_epochs 5
```


# Contact

- Issue(å»ºè®®)ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/nerpy.svg)](https://github.com/shibing624/nerpy/issues)
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼š
åŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624, å¤‡æ³¨ï¼šå§“å-å…¬å¸-NLP* è¿›NLPäº¤æµç¾¤ã€‚

<img src="docs/wechat.jpeg" width="200" />


# Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†nerpyï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

APA:
```latex
Xu, M. nerpy: Named Entity Recognition Toolkit (Version 0.0.2) [Computer software]. https://github.com/shibing624/nerpy
```

BibTeX:
```latex
@software{Xu_nerpy_Text_to,
author = {Xu, Ming},
title = {{nerpy: Named Entity Recognition Toolkit}},
url = {https://github.com/shibing624/nerpy},
version = {0.0.2}
}
```

# License


æˆæƒåè®®ä¸º [The Apache License 2.0](LICENSE)ï¼Œå¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ nerpyçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚


# Contribute
é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

 - åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
 - ä½¿ç”¨`python -m pytest -v`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚

# Reference
- [transformers](https://github.com/huggingface/transformers)
